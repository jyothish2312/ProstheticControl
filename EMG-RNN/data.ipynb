{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing .csv\n",
    "\n",
    "### Changes made to your data\n",
    "* `Extension.csv`\n",
    "  - Added 0-timestep for first sample. It was missing.\n",
    "  - Removed the last sample, as it was incomplete.\n",
    "  - Removed `-,-,-,-` at the end.\n",
    "* `Flexion.csv`\n",
    "  - Removed the last sample, as it was incomplete.\n",
    "  - Removed `-,-,-,-` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = pd.read_csv('./Extension.csv') # pd.read_csv('./testExt.csv')\n",
    "flex = pd.read_csv('./Flexion.csv') # pd.read_csv('./testFlex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numpy(df):\n",
    "    df = df[df['TimeCoordinate'] != '-'] # Drop rows with '-' in 'TimeCoordinate' column\n",
    "    # NOTE: LSTM inherently has a time component, so we don't need to keep track of time\n",
    "    df = df.drop(df.columns[[0]], axis=1) # Drop 'TimeCoordinate' column\n",
    "    df = df.drop(df.columns[[-1]], axis=1) # Drop 'Label' column\n",
    "    return df.values.astype(float)\n",
    "\n",
    "ext_np = convert_to_numpy(ext)\n",
    "flex_np = convert_to_numpy(flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext.shape, ext_np.shape, flex.shape, flex_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3200 // 20, 3020 // 20 # <-- Number of samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_np = ext_np.reshape(-1, 20, 2)\n",
    "flex_np = flex_np.reshape(-1, 20, 2)\n",
    "\n",
    "ext_np.shape, flex_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels\n",
    "ext_labels = np.zeros(ext_np.shape[0]) # NOTE: 0-class\n",
    "flex_labels = np.ones(flex_np.shape[0]) # NOTE: 1-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two classes\n",
    "X = np.concatenate((ext_np, flex_np), axis=0)\n",
    "y = np.concatenate((ext_labels, flex_labels), axis=0)\n",
    "\n",
    "# Randomly shuffle the data only along the first axis for X and y\n",
    "perm = np.random.permutation(len(X))\n",
    "\n",
    "X_shuffled = X[perm]\n",
    "y_shuffled = y[perm]\n",
    "\n",
    "X_shuffled, y_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled[1], y_shuffled[1] # Compare with the original csv, as a check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled.shape, y_shuffled.shape # 311 samples - 160 extension, 151 flexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving both to compressed .npz file\n",
    "# np.savez(\"./shuffled_data.npz\", X=X_shuffled, y=y_shuffled) # shuffled_test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking X.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load from .npz file\n",
    "dat = np.load(\"./shuffled_data.npz\") # shuffled_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dat['X'], dat['y'] # Shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1], y[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "- [ ] sklearn.preprocessing.RobustScaler (IQR)\n",
    "- [ ] sklearn.preprocessing.MinMaxScaler (0-1)\n",
    "- [ ] sklearn.preprocessing.StandardScaler (Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load from .npz file\n",
    "dat = np.load(\"./shuffled_data.npz\") # shuffled_test_data\n",
    "\n",
    "X, y = dat['X'], dat['y'] # Shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# apply the fit_transform method on each sample along the second axis\n",
    "X_scaled = np.empty_like(X)\n",
    "for i in range(X.shape[0]):\n",
    "    X_scaled[i,:,:] = scaler.fit_transform(X[i,:,:])\n",
    "\n",
    "# Compare with manually scaled data\n",
    "X_mm = (X[0] - X[0].min(axis=0)) / (X[0].max(axis=0) - X[0].min(axis=0))\n",
    "X_ss = (X[0] - X[0].mean(axis=0)) / X[0].std(axis=0)\n",
    "X_rs = (X[0] - np.median(X[0], axis=0)) / (np.quantile(X[0], 0.75, axis=0) - np.quantile(X[0], 0.25, axis=0))\n",
    "np.allclose(X_mm, X_scaled[0]), np.allclose(X_ss, X_scaled[0]), np.allclose(X_rs, X_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((311, 20, 2), (311, 20, 2))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaled data to .npz file\n",
    "np.savez(\"./robustscaled_data.npz\", X=X_scaled, y=y) # minmaxscaled_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mix data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load from .npz file\n",
    "dat_orig = np.load(\"./shuffled_data.npz\") # shuffled_test_data\n",
    "dat_new = np.load(\"./shuffled_test_data.npz\") # shuffled_test_data\n",
    "\n",
    "# X, y = dat['X'], dat['y'] # Shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((311, 20, 2), (50, 20, 2), (311,), (50,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_orig['X'].shape, dat_new['X'].shape, dat_orig['y'].shape, dat_new['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix, y_mix = np.r_[dat_orig['X'], dat_new['X']], np.r_[dat_orig['y'], dat_new['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"./unshuffled_mix_data.npz\", X=X_mix, y=y_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((361, 20, 2), (361,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load from .npz file\n",
    "dat = np.load(\"./unshuffled_mix_data.npz\") # shuffled_test_data\n",
    "\n",
    "X, y = dat['X'], dat['y'] # Shuffled data\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
